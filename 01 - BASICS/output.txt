So what we have seen so far is the following we have looked at what was a random variable,we defined what is a random variable and then we looked at the types of random variablenamely we said that there are two main types of a random variable we can classify themas discrete random variable and continuous random variables.Then we looked at when we focus our, we restricted our focus only to discrete random variables,in discrete random variables we defined what was a probability mass function in the sensethat you are interested in knowing about a distribution of a random variable, hence weintroduced the notion of a probability mass function.The probability mass function tells us about the probability distribution of a random variableand the cumulative distribution function helps us to know what is the overall distributionof the random variable given a real line.So, we also looked at the graphs of both the probability mass function and the cumulativedistribution function.Then we went out to introduce an extremely important notion of a random variable namelythe expectation of a random variable, we focused on properties of a random variable and thenafter this we looked at how we you can compute the expectation of functions of a random variable.Today we are going to focus on another important summary of a random variable which we referto as a variance of a random variable.So, let us first of all motivate the need for such a measure.So we saw that we also realize that we can interpret the expected value as a long-runaverage, so in other words the way we introduced the expected value of a random variable wasas a weighted average of possible values the random variable can take, in other words ifX can take values x1 x2 xn I am assuming finitely many with probability X equal to xi equalto P1 P2 Pn these are I assume P1 P2 Pn are the weights given to the values, then I knowthat the expectation of X can be written as P1x1 plus P2x2 plus Pnxn, in other words itis X is taking possible values x1 x2 to xn with weights P1 P2 to Pn then expectation02:57of X can be expressed as a weighted average of the possible values of random variable.Now, let us look at an example where I have three random variables.So, what are these three random variables, X is a random variable with probability 1,Y is a random variable which takes the values minus 2 with probability half and plus 2 withprobability half and Z is a random variable which takes the value minus 20 with probabilityhalf and plus 20 with probability half.Now if you compute X, I can write X takes the value 0 with probability X equal to iequal to 1 which gives me the expectation of X is 0 into 1 which is equal to 0.Similarly, I know Y takes the value minus 2 and plus 2 with probability Y equal to iequal to half and half giving me expectation of Y equal to minus 2 into half plus 2 intohalf which is again a 0.Z takes the value minus 20 and 20 with probability Z is equal to i is again half and half whichgives me expectation of Z, which is equal to minus 20 into half plus 20 into half whichis again 0.So, I can see that expectation of X equals expectation of Y equals expectation of Z,so this expected value however what we notice is though the expectation is same the distributionof these random variables with the terms of the values they take is different.In other words, the expected value of a random variable does not tell us anything about thespread or the variation.Hence, I need a measure for the spread.What I can notice here although is the spread of Z is greater than the spread of Y whichis greater than the spread of X.The expected value although was the same expected value of X equal to expected value of Y equalto expected value of Z which is equal to 0.Hence, I need a measure of spread and just as what we did in a descriptive statisticsmodule mean gave us a measure of central tendency variance gave us a measure of spread.So, we are going to define the variance of a random variable, which is a measur

e of spread.So, what how do I define the variance of a random variable?So, let me denote the expected value of a random variable by the Greek alphabet mu thatis expectation of X is equal to mu, X is my random variable I see how far is X from mu,I take the square of the difference and the expected value of the squared difference andthat is what I am going to define as my variance of X.So, the if X is a random variable with expected value mu then the variance of X is definedby expectation of X minus mu whole square.In other words, the variance of a random variable defines the square of the difference of therandom variable from its mean on an average.I repeat, the variance of a random variable measures the difference of the random variablefrom its mean, so that is X minus mu, it measures the square of the difference which is X minusmu whole square on an average is expectation of X minus mu whole square.So, when I talk about X minus mu whole square the question is can I computationally havea more convenient formula to compute the variance of a random variable?I know variance of a random variable is expectation of X minus mu whole square.Now, let us look at X minus mu whole square, I know X minus mu whole square is X squareplus mu square minus 2 times mu into X.Now, recall from my expectation or properties of expectation, expectation of aX plus b wherea and b are constants as a times expectation of X plus b.So, mu is a constant here, so if I am looking at expectation of X minus mu whole square,I know this is equal to expectation of X square plus mu square minus 2 times mu of X whichI can write it as expectation of X square plus expectation of mu square is going tobe mu square minus 2 mu times expectation of X, I know expectation of X is a mu, hencethis reduces to expectation of X square plus mu square minus 2 mu into mu which gives meexpectation of X square minus mu square.So, the computational formula for X is a very simple formula which is the same as varianceof X is expectation of X square minus mu square, where mu is expectation of X.So, now let us apply this formula to compute the variance of the random variables whichwe have discussed earlier.Let us begin with the role of a fair dice and I am rolling it once I know the samplespace is 1, 2, 3, 4, 5, 6, X is the outcome of the roll, so my X takes values 1, 2, 3,4, 5, 6, I am going to apply the formula the computational formula variance of X is expectationof X square minus expectation of X whole square or expectation of X square minus mu square.That is the formula I am going to apply.So, if X takes the value 1, 2, 3, 4, 5, 6, I know X square takes the value 1 square,2 square is a 4, 3 square is a 9, 4 square is a 16, 5 square is a 25 and 6 square isa 36.Now, if X takes the value 1, X square takes the value 1 with the same probability.Similarly, if X takes the value 2, X square takes the value 4 with probability 1 by 6,X takes the value 3, X square takes the value 9 with probability 1 by 6 and so forth X takesthe value i, X square takes the value i square with probability 1 by 6.We have already computed expectation of X and we notice that expectation of X was 3.5.So, what is expectation of X square?X square takes the value 1 with probability 1 by 6, 4 with probability 1 by 6, 9 withprobability 1 by 6, 16 with probability 1 by 6, 25 with probability 1 by 6 and 36 withprobability 1 by 6, which gives me expectation of X square is 15.167, if expectation of Xis 3.5 expectation of X whole square is 3.5 square and hence my variance of X is 15.167which is expectation of X square minus mu square which is 2.917.Similarly, let us look at the example of rolling a dice twice, again we know that X takes values2, 3, 4 up to 12, hence X square takes the values 4, 9, 16, 25 up to 144, again the probabilitywith which X takes the value 2 is same as the probability with which X takes the valueX square takes the value 4 which is equal to 1 by 6 in this case and hence my expectationof X we have alread

y computed was 7, I can verify that expectation of X square is 54.833giving me variance of X is 5.833.So, we notice the following that in the earlier case when X was a roll of a dice it took thevalue 1, 2, 3, 4, 5, 6, it had equal probability and now you can see that the mean was around3.5 this was somehow balancing it, here the mean is at 7 and I can see that the variancein this case is 5.833 because it is taking a value from 2 to 12, so the variability ismore, here it is taking the value 1 to 6 and it had a variance of about 2.91.Now, let us apply the formula to tossing a coin thrice, again I know that X is a randomvariable which takes the values, again I know X is a random variable which takes the values0, 1, 2, 3, hence X square is equal to 0, 1, 4 and 9 with the same probabilities, soI can verify that expectation of X, I already have checked.Expectation of X was 3 by 2, expectation of X square is going to be 0 into 1 by 8 plus1 into 3 by 8 plus 4 into 3 by 8 plus 9 into 1 by 8 that would be my expectation of X squarewhich I can verify that to be 24 by 8, which is 3.Hence, my variance of X is 3 minus 2.25 which is 0.5, because this is 1.5, 1.5 square is2.25 variance of X is 3 minus 2.25 which is a 0.75.Again, you can see that the value of X is between 0 and 3, so I had when X took thevalue 1, 2, 3, 4, 5, 6 with equal probability I had a variance of 2.91, X took the value2, 3, 4 up to 12 with varied probabilities, then I had 5.83, now X is again taking thevalue 0, 1, 2, 3 with probability 1 by 8, 3 by 8, 3 by 8 and 1 by 8, my variance isvery less which is 0.75.So, now let us look at the specific random variables which we have already defined recallwe defined a Bernoulli random variable as that random variable which takes only 2 valuesfor convenience I assumed it took the value 0 and 1 with probability X taking value 0as 1 minus p and value 1 equal to p, if X takes the value 0 and 1, X square also takesthe value 0 and 1 with the same probability is 1 minus p and p.We verified that expectation of X is 0 into 1 minus p plus 1 into p, which gave me theexpectation of X equal to p, expectation of X square is also 0 into 1 minus p plus 1 intop which is p, hence the variance equal to expectation of X square which is equal top minus expectation of X whole square which is minus p square, which I can write as pinto 1 minus p.Hence the variance of a Bernoulli random variable is p into 1 minus p.So, I can refer to this as if x is a Bernoulli random variable with parameter p, then theexpectation of X is p, the variance of X is p into 1 minus p.Let us, look at that case of a discrete uniform random variable, again I know I call a randomvariable to be a uniformly distributed random variable if X takes the value 1, 2 up to nwith probability 1 by n, 1 by n, 1 by n, again an example of this is my roll of a singledice where my n was 6 and I knew that probability X equal to each value is 1 by 6, 1 by 6, 1by 6.So, if X takes these values then X square takes the value 1, 4 up to n square, the probabilitiesremain the same.We have already seen the expectation of X equal to 1 into 1 by n plus 2 into 1 by nplus n into 1 by n which we showed was 1 by n into the sum of the first n natural numberswhich we further saw that this was n into n plus 1 by 2 into 1 by n which gave me nplus 1 by 2.So, I already verified that expectation of X equal to n plus 1 by 2, now when n equalto 6, I know that this is equal to 7 by 2, which is 3.5 and this 3.5 actually matcheswith my expectation of a single roll of a dice that is 3.5, recall, I got a 3.5 whenI found out the expectation of rolling a dice 1 was 3.5.Now, from here remember the variance was 2.91, so let us go and check for a discrete randomvariable.So, again when I go and do my check for a discrete random variable I see that what isexpectation of X square in this case.Now, if I look at X square X square takes the value 1 plus 4 plus n square so I knowexpectation of X square, I can write it as 1 by so expectati

on of x square I can writeit as 1 by n into 1 plus 1 by n into 4 plus 1 by n into n square, so I get 1 by n plus1 plus 2 square plus 3 square plus n square, the term within the brackets is nothing butthe sum of the squares of the first n natural numbers.And we can verify and we already know that the expectation of n square is nothing butn plus 1 into 2 n plus 1 by 6, because the sum of squares is n into n plus 1 into 2 nplus 1 by 6.Now, the variance of X is going to be n plus 1 into 2 n plus 1 by 6 minus n plus 1 wholesquare by 4, this is expectation of X square, this is expectation of X whole square andI can show that this would be this is going to be a 2 n square.plus 3 n plus 1 minus n square plus 1 plus 2 n by 4 by 6 and I can verify that this isgoing to be 2 n square plus 12 n minus 12 n cancel out plus 4 minus 6, which is equalto minus 2 by 24 which gives me the fact that variance of X is n square minus 1 by 12.So, we computed the variance of very well-known distributions namely the Bernoulli distributionand the discrete uniform distribution.We will be looking at a few more distributions later, but for now in summary, we introducedthe notion of a variance, the notion of a variance of a random variable captures themeasure of spread, hence it is an important measure and we also computed through the computationalformula and the computational formula is variance of X is expectation of X square minus theexpectation of X whole square which is the same as expectation of X square minus mu square,we applied this formula to compute the variance of some well-known distributions and examplesthat we have already seen.

